# üéÅ TrouveUnCadeau.xyz - Backend API

API de recommandations de cadeaux avec intelligence artificielle multi-LLM optimis√©e.

**Architecture:** Multi-LLM (Together.ai + Gemini + Claude) avec cache Redis  
**√âconomie:** 99% vs OpenAI pur ($65/mois vs $650/mois)  
**D√©ploiement:** Optimis√© pour Render.com

---

## üöÄ D√©ploiement Rapide sur Render.com

### Pr√©requis
- Compte GitHub
- Compte Render.com (gratuit)
- Cl√©s API: Together.ai, OpenAI, Airtable

### √âtapes

1. **Fork/Clone ce repo**
```bash
git clone https://github.com/votre-username/render-trouveuncadeau.git
cd render-trouveuncadeau
```

2. **Push vers votre GitHub**
```bash
git remote set-url origin https://github.com/votre-username/render-trouveuncadeau.git
git push -u origin main
```

3. **D√©ployer sur Render.com**
   - Cr√©er un nouveau "Blueprint" depuis votre repo
   - Render d√©tectera automatiquement `render.yaml`
   - Ajouter les variables d'environnement (secrets):
     - `TOGETHER_API_KEY`
     - `OPENAI_API_KEY`
     - `AIRTABLE_API_KEY`
     - `AIRTABLE_BASE_ID`
     - `GEMINI_API_KEY` (optionnel)
     - `CLAUDE_API_KEY` (optionnel)

4. **Deploy!**
   - Render build et d√©ploie automatiquement
   - API accessible √†: `https://trouveuncadeau-api.onrender.com`
   - Docs interactives: `https://trouveuncadeau-api.onrender.com/docs`

**C'est tout!** ‚ú®

---

## üìÅ Structure du Projet

```
render-trouveuncadeau/
‚îú‚îÄ‚îÄ app.py                    # FastAPI application principale
‚îú‚îÄ‚îÄ config.py                 # Configuration centralis√©e
‚îú‚îÄ‚îÄ cache_manager.py          # Gestion cache Redis
‚îú‚îÄ‚îÄ multi_llm_router.py       # Routing intelligent multi-LLM
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îú‚îÄ‚îÄ render.yaml              # Configuration Render.com
‚îú‚îÄ‚îÄ .env.example             # Template variables d'environnement
‚îú‚îÄ‚îÄ .gitignore               # Git ignore
‚îî‚îÄ‚îÄ README.md                # Ce fichier
```

---

## üèóÔ∏è Architecture

### Routing Multi-LLM

L'application route intelligemment les requ√™tes vers le LLM optimal:

| Complexit√© | LLM | % Trafic | Co√ªt/1M tokens | Usage |
|-----------|-----|----------|----------------|-------|
| **Simple** | Together.ai (Mixtral) | 90% | $0.06 | Requ√™tes standard |
| **Moyenne** | Gemini Flash 2.0 | 8% | **GRATUIT** | Contexte riche |
| **Complexe** | Claude Haiku | 2% | $0.25 | Analyses pouss√©es |

### Cache Redis

- **Hit rate cible:** 80%+
- **TTL:** 7 jours (configurable)
- **√âconomie:** R√©duit les appels LLM de 80%
- **Graceful degradation:** Fonctionne m√™me si Redis down

### Calcul d'√âconomie

**Sc√©nario:** 1000 requ√™tes/jour (30k/mois)

| Provider | Co√ªt mensuel | √âconomie |
|----------|--------------|----------|
| **OpenAI pur** | $650 | - |
| **Architecture optimis√©e** | $65 | **99%** üéâ |

*D√©tails:*
- Together.ai (90%): $54/mois
- Gemini (8%): $0/mois (gratuit!)
- Claude (2%): $11/mois
- **Total: $65/mois**

---

## üõ†Ô∏è D√©veloppement Local

### Installation

```bash
# 1. Clone le repo
git clone https://github.com/votre-username/render-trouveuncadeau.git
cd render-trouveuncadeau

# 2. Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Installer d√©pendances
pip install -r requirements.txt

# 4. Configuration
cp .env.example .env
# √âditer .env avec vos cl√©s API

# 5. D√©marrer Redis (optionnel)
# Option A: Docker
docker run -d -p 6379:6379 redis:alpine

# Option B: Installation locale
# macOS: brew install redis && redis-server
# Ubuntu: sudo apt install redis-server && redis-server
# Windows: https://redis.io/download

# 6. Lancer l'API
python app.py
```

L'API sera accessible √† `http://localhost:8000`

### Tests

```bash
# Health check
curl http://localhost:8000/health

# Test recommandation
curl -X POST http://localhost:8000/api/recommendations \
  -H "Content-Type: application/json" \
  -d '{
    "query": "cadeau pour maman qui aime lire, budget 50$",
    "context": {"occasion": "anniversaire"}
  }'

# Voir les stats
curl http://localhost:8000/api/stats
```

### Documentation Interactive

Visitez `http://localhost:8000/docs` pour l'interface Swagger UI.

---

## üîå API Endpoints

### `GET /health`
Health check de l'application

**Response:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "environment": "production",
  "cache_enabled": true,
  "llm_providers": {
    "together": true,
    "gemini": true,
    "claude": true,
    "openai": true
  }
}
```

### `POST /api/recommendations`
Obtenir des recommandations de cadeaux

**Request:**
```json
{
  "query": "cadeau pour papa qui aime le golf, budget 100$",
  "context": {
    "occasion": "f√™te des p√®res",
    "age": 55
  },
  "force_provider": "together"  // Optionnel
}
```

**Response:**
```json
{
  "recommendations": "Je vous recommande...",
  "llm_used": "together.ai",
  "cached": false,
  "cost_usd": 0.00012,
  "tokens": {
    "input": 150,
    "output": 200,
    "total": 350
  }
}
```

### `GET /api/stats`
Statistiques d'utilisation

**Response:**
```json
{
  "cache": {
    "hits": 850,
    "misses": 150,
    "hit_rate": 0.85,
    "enabled": true
  },
  "llm_routing": {
    "total_requests": 1000,
    "total_cost_usd": 65.43,
    "distribution": {
      "together": {
        "count": 900,
        "percentage": 90.0,
        "cost_usd": 54.00
      },
      "gemini": {
        "count": 80,
        "percentage": 8.0,
        "cost_usd": 0.00
      },
      "claude": {
        "count": 20,
        "percentage": 2.0,
        "cost_usd": 11.43
      }
    }
  }
}
```

### `POST /api/cache/clear`
Vider le cache (admin)

**Response:**
```json
{
  "status": "success",
  "message": "Cache vid√© avec succ√®s"
}
```

### `GET /api/config`
Configuration sanitiz√©e (sans secrets)

---

## ‚öôÔ∏è Configuration

### Variables d'Environnement

Voir `.env.example` pour la liste compl√®te.

**Variables Requises:**
```bash
TOGETHER_API_KEY=xxx        # Provider principal
OPENAI_API_KEY=xxx         # Pour embeddings
AIRTABLE_API_KEY=xxx       # Base de donn√©es produits
AIRTABLE_BASE_ID=xxx       # ID de la base Airtable
```

**Variables Optionnelles:**
```bash
GEMINI_API_KEY=xxx         # Provider secondaire (gratuit!)
CLAUDE_API_KEY=xxx         # Provider tertiaire (qualit√© max)
REDIS_HOST=localhost       # Cache
REDIS_PORT=6379
REDIS_ENABLED=true
```

### Obtenir les Cl√©s API

- **Together.ai:** https://api.together.xyz/signup
- **OpenAI:** https://platform.openai.com/api-keys
- **Gemini:** https://makersuite.google.com/app/apikey
- **Claude:** https://console.anthropic.com/
- **Airtable:** https://airtable.com/account

---

## üìä Monitoring

### M√©triques Disponibles

- **Cache:** Hit rate, hits/misses, erreurs
- **LLM Routing:** Distribution par provider, co√ªts par provider
- **Performance:** Latence, tokens utilis√©s
- **Co√ªts:** Tracking en temps r√©el par provider

### Logs

```bash
# Logs en production (Render.com)
# Visibles dans le dashboard Render

# Logs en local
# Affich√©s dans le terminal
```

### Alertes

Pour production, int√©grer:
- **Sentry:** Erreurs et exceptions
- **DataDog:** M√©triques et APM
- **Better Uptime:** Uptime monitoring

---

## üîê S√©curit√©

- ‚úÖ Secrets jamais committ√©s (`.gitignore`)
- ‚úÖ Validation Pydantic des inputs
- ‚úÖ Rate limiting (TODO)
- ‚úÖ CORS configur√©
- ‚úÖ Environnements s√©par√©s (dev/staging/prod)

**TODO Production:**
- [ ] Ajouter authentification API key
- [ ] Impl√©menter rate limiting
- [ ] HTTPS obligatoire
- [ ] Logging structur√© (JSON)

---

## üö® Troubleshooting

### API ne d√©marre pas

**Probl√®me:** Erreur au d√©marrage
**Solution:**
```bash
# V√©rifier les cl√©s API
python -c "from config import get_settings; s=get_settings(); print(s.get_summary())"

# V√©rifier d√©pendances
pip install -r requirements.txt --upgrade
```

### Cache ne fonctionne pas

**Probl√®me:** Redis unavailable
**Solution:**
```bash
# V√©rifier Redis
redis-cli ping  # Doit retourner PONG

# D√©sactiver cache si besoin
export REDIS_ENABLED=false
```

### Co√ªts trop √©lev√©s

**Probl√®me:** D√©passement budget
**Solution:**
1. V√©rifier hit rate cache: `curl /api/stats`
2. Augmenter TTL Redis si < 80%
3. V√©rifier distribution LLM (doit √™tre ~90/8/2)
4. Impl√©menter rate limiting

---

## üìà Roadmap

### Version 1.0 (Actuel)
- [x] Architecture multi-LLM
- [x] Cache Redis
- [x] Routing intelligent
- [x] API FastAPI
- [x] D√©ploiement Render.com

### Version 1.1 (Q1 2025)
- [ ] Authentification API key
- [ ] Rate limiting
- [ ] Logging structur√©
- [ ] Monitoring avanc√©
- [ ] Tests unitaires

### Version 2.0 (Q2 2025)
- [ ] Int√©gration FAISS vector search
- [ ] Personnalisation utilisateur
- [ ] Historique de recommandations
- [ ] A/B testing LLMs
- [ ] Dashboard admin

---

## ü§ù Contribution

Les contributions sont bienvenues!

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit (`git commit -m 'Add AmazingFeature'`)
4. Push (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

---

## üìÑ Licence

MIT License - voir LICENSE pour d√©tails

---

## üôè Remerciements

- **Together.ai** pour l'API abordable
- **Google** pour Gemini Flash gratuit
- **Anthropic** pour Claude Haiku
- **Render.com** pour l'h√©bergement simplifi√©

---

## üìû Support

- **Issues:** https://github.com/votre-username/render-trouveuncadeau/issues
- **Email:** contact@trouveuncadeau.xyz
- **Docs:** https://trouveuncadeau-api.onrender.com/docs

---

**Fait avec ‚ù§Ô∏è au Qu√©bec üá®üá¶**
